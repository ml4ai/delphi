{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backcasting Demo Notebook\n",
    "\n",
    "_Loren Champlin_\n",
    "\n",
    "Adapted from _Adarsh Pyarelal_'s WM 12 Month Evaluation Notebook \n",
    "\n",
    "As always, we begin with imports, and print out the commit hash for a rendered\n",
    "version of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "from delphi.visualization import visualize\n",
    "import delphi.jupyter_tools as jt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "#Comment out the next line if you do not have the delphi.db file. \n",
    "from delphi.db import engine\n",
    "jt.print_commit_hash_message()\n",
    "import random as rm\n",
    "import delphi.evaluation as EN\n",
    "import delphi.AnalysisGraph as AG\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "from indra.statements import (\n",
    "    Concept,\n",
    "    Influence,\n",
    "    Evidence,\n",
    "    Event,\n",
    "    QualitativeDelta,\n",
    ")\n",
    "from delphi.utils.indra import *\n",
    "from delphi.utils.shell import cd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from delphi.utils.fp import flatMap, take, ltake, lmap, pairwise, iterate, exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(87)\n",
    "rm.seed(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = {\n",
    "    \"conflict\": {\n",
    "        \"grounding\": \"UN/events/human/conflict\",\n",
    "        \"delta\": {\"polarity\": 1, \"adjective\": [\"small\"]},\n",
    "    },\n",
    "    \"food security\": {\n",
    "        \"grounding\": \"UN/entities/human/food/food_security\",\n",
    "        \"delta\": {\"polarity\": -1, \"adjective\": [\"large\"]},\n",
    "    },\n",
    "    \"migration\": {\n",
    "        \"grounding\": \"UN/events/human/human_migration\",\n",
    "        \"delta\": {\"polarity\": 1, \"adjective\": ['small']},\n",
    "    },\n",
    "    \"product\": {\n",
    "        \"grounding\": \"UN/entities/natural/crop_technology/product\",\n",
    "        \"delta\": {\"polarity\": 1, \"adjective\": ['large']},\n",
    "    },\n",
    "    \"economic crisis\": {\n",
    "        \"grounding\": \"UN/events/human/economic_crisis\",\n",
    "        \"delta\": {\"polarity\": 1, \"adjective\": [\"large\"]},\n",
    "    },\n",
    "    \"precipitation\": {\n",
    "        \"grounding\": \"UN/events/weather/precipitation\",\n",
    "        \"delta\": {\"polarity\": 1, \"adjective\": []},\n",
    "    },\n",
    "    \"inflation\": {\n",
    "        \"grounding\": \"UN/entities/human/financial/economic/inflation\",\n",
    "        \"delta\": {\"polarity\": 1, \"adjective\": [\"large\"]},\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "def make_event(concept, attrs):\n",
    "    return Event(\n",
    "        Concept(\n",
    "            attrs[\"grounding\"],\n",
    "            db_refs={\"TEXT\": concept, \"UN\": [(attrs[\"grounding\"], 0.8)]},\n",
    "        ),\n",
    "        delta=QualitativeDelta(\n",
    "            attrs[\"delta\"][\"polarity\"], attrs[\"delta\"][\"adjective\"]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def make_statement(event1, event2):\n",
    "    return Influence(\n",
    "        event1,\n",
    "        event2,\n",
    "        evidence=Evidence(\n",
    "            annotations={\n",
    "                \"subj_adjectives\": event1.delta.adjectives,\n",
    "                \"obj_adjectives\": event2.delta.adjectives,\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "events = {\n",
    "    concept: make_event(concept, attrs) for concept, attrs in concepts.items()\n",
    "}\n",
    "\n",
    "s1 = make_statement(events[\"conflict\"], events[\"food security\"])\n",
    "s2 = make_statement(events[\"migration\"], events[\"product\"])\n",
    "s3 = make_statement(events[\"migration\"], events[\"economic crisis\"])\n",
    "s4 = make_statement(events[\"precipitation\"], events[\"inflation\"])\n",
    "s5 = make_statement(events[\"inflation\"],events[\"migration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the Causal Analysis Graph (CAG). This is CAG was inferred by reading in a JSON corpus and was pruned and adjusted to be human migration centered. Also is a list of the nodes contained in the CAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with open(\"../scripts/build/migration_centered_CAG.pkl\",'rb') as f:\n",
    "    #G = pickle.load(f)\n",
    "\n",
    "G = AG.AnalysisGraph.from_statements(get_valid_statements_for_modeling([s5]))\n",
    "\n",
    "for n in G.nodes(data=True):\n",
    "    print(n[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we map indicator variables to nodes. For the most part indicator variables can be inferred from available data and texts, but we can also manually map indicators to nodes. There is also a list of the indicator variables in the same order as the list of nodes above (i.e \"Claims on other sectors of the domestic economy\" is attached to \"UN/events/human/economic_crisis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.map_concepts_to_indicators()\n",
    "\n",
    "G.set_indicator(\"UN/events/human/human_migration\", \"New asylum seeking applicants\", \"UNHCR\")\n",
    "G.set_indicator(\"UN/entities/human/financial/economic/inflation\", \"Inflation Rate\", \"ieconomics.com\")\n",
    "#G.set_indicator(\"UN/entities/human/food/food_security\", \"IPC Phase Classification\", \"FEWSNET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(G, indicators=True, indicator_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN.train_model(G,2015,1,2015,12,1000,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in G.nodes(data=True):\n",
    "    for indicators in n[1][\"indicators\"].values():\n",
    "        print(indicators.name,\" \",indicators.mean,\" \",indicators.stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.training_latent_state_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN.generate_predictions(G,2015,12,2016,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN.pred_plot(G,'New asylum seeking applicants',plot_type='Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the setup_evaluate function from the Evaluation module to set the sampling resolution and assemble the transition model from our gradable adjectives data. This is just a simple helper function since all of this can be done manually using the AnalysisGraph functions as well. Instead of passing the CAG (G in this case) directly, there is an optional input variable that takes a string representing a pickle file that contains the appropriate CAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****Section below is Under Construction****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we visualize the CAG parameterized with indicator values for January, 2012. Also note that you can specifiy units for a particular indicator variables using a dictionary object where the keys are the indicator variable names and the values are the specified units. Default units are used if the selected units for an indicator variable do not exist. \n",
    "\n",
    "Legend for visualization: \n",
    "- Red edge: overall inhibition, green edge: overall promotion\n",
    "- Edge thickness corresponds roughly to the 'strength' of the influence.\n",
    "- Edge opacity corresponds roughly to the number of evidence fragments \n",
    "  that support the causal relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = {\"Claims on other sectors of the domestic economy\": \"annual growth as % of broad money\"}\n",
    "visualize(G, indicators=True, indicator_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate our CAG and transition model by predicting Net Migration given changes in Economic Crisis. The first four variables are self-explanatory, they set the time range of the evaluation. Right now I have it set to evaluate from January, 2012 to January, 2017. Passing None to start_month and end_month ensures that the CAG is parameterized correctly since only 2012 (with no month by month granularity) exists in our current database for \"Net Migration\". After parameterized we treat None (in the case of the months) as month 1 (or January). \n",
    "\n",
    "Next, we want to predict and evaluate Net Migration which is the indicator variable attached to the Human Migration node. This can be seen by the string that is passed to \"target_node\" which is the full name of Human Migration. For example if we instead wanted to evaluate \"Conflict incidences\", then we would pass a string representing the full name of the Conflict. \n",
    "\n",
    "The variable \"intervened_node\" contains a string that represents the node we wish to intervene on or forcefully change to faciliate our predictions. In this case, we are intervening on Economic Crisis. The belief is that the node changes at the same rate in which its attached indicator node does. So we use the data for \"Claims on other sectors of the domestic economy\" to infer rates of change for Economic Crisis.\n",
    "\n",
    "The function evaluate from the Evaluation module returns a pandas dataframe containing the predicted values, true values, and residuals (error) for the indicator variable attached to the specified target node. Setting plot = True also displays a plot representing this data. plot_type = 'Compare' gives a plot that compares the predicted values and true values per time step. Changing plot_type = 'Error' gives a residual (Error) plot with a reference line at 0. \n",
    "\n",
    "Also note that G, the variable containing the CAG was also passed into evaluate. There is also a optional input argument for evaluate (like setup_evaluate) which takes a string representing a pickle file containing the appropriate CAG.\n",
    "\n",
    "*Note: Not shown below, but evaluate can take in all of the same arguments as parameterize() such as country, state, units,etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the Predicted and True values for Net Migration along with the Errors (residuals) between them. Notice that the table is indexed by date (Year-Month)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the data values for both the target node and intervened node. These cells are mostly so one can see the available indictor variable data and adjust the values above accordingly. delphi.db is needed for these cells and if you don't have it, you would need to comment out from delphi.db import engine to run the rest of the notebook. You'll note that \"Claims on other sectors of the domestic economy\" has two types of units. Since no units were specified to evaluate(), it uses the same default settings as parameterize() to select units to use. In the above case, \"% of GDP\" is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \" \".join(\n",
    "        [\n",
    "            f\"select * from indicator\",\n",
    "            f\"where `Variable` like 'New asylum seeking applicants'\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "results = engine.execute(query)\n",
    "\n",
    "pd.DataFrame(results, columns=results.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
